{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Any, Union, Tuple, Callable, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure reproducibility\n",
    "SEED = 26\n",
    "\n",
    "# torch related\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# others\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling module\n",
    "\n",
    "We implement a sampling layer corresponding to the reparametrization trick.\n",
    "The input for the forward procedure is a tuple containing the mean and the log of the diagonal of the covariance matrix for the posterior distribution $P(z|x)$.\n",
    "\n",
    "You need to implement the following procedure:\n",
    "* sample $\\epsilon$ from a standard normal $N(0, I)$\n",
    "* return $z_{mean} + \\exp(0.5 \\cdot z_{log-var}) \\cdot \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Sampling, self).__init__(**kwargs)\n",
    "    \n",
    "    def forward(self, inputs: Tuple[torch.tensor, torch.tensor]) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs\n",
    "            tuple containing z_mean and z_log_var representing\n",
    "            the mean and the log of the diagonal of the convariance\n",
    "            matrix corresponding to the posterior distribution of\n",
    "            latent variable\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            sample from the posterior distribution\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = inputs\n",
    "        \n",
    "        # TODO 1\n",
    "        # For this task you have to implement the sampling procedure\n",
    "        eps =  torch.rand_like(z_mean) # sample from a standard normal \n",
    "        z   =  z_mean + torch.exp(0.5 * z_log_var) * eps # use the reparametrization trick to sample from the posterior\n",
    "        return z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int = 2, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim\n",
    "            the dimension of the laten variable. We will use 2\n",
    "            for visualization purposes.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        \n",
    "        # define network architecture\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, padding=1, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, padding=1, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 16)\n",
    "        \n",
    "        # TODO 2\n",
    "        # Add the two heads of the encoder corresponding\n",
    "        # to the mean and the log_var of the posterior distribution\n",
    "        #\n",
    "        # Both of the should have an input of 16 and the output \n",
    "        # equal to latent dim\n",
    "        self.fc_mean    =  nn.Linear(16, latent_dim) # mean head\n",
    "        self.fc_log_var =  nn.Linear(16, latent_dim) # log var head\n",
    "        \n",
    "        # define sampling layer\n",
    "        self.sampling = Sampling()\n",
    "        \n",
    "    def forward(self, inputs: torch.tensor) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs\n",
    "            tensor containing the input image (B x C x H x W)\n",
    "            \n",
    "        Returns\n",
    "            z_mean, z_log_var, z representing the mean of the posterior,\n",
    "            log of diagonal covariance matrix, sample from the posterior\n",
    "        \"\"\"\n",
    "        \n",
    "        x = F.relu(self.conv1(inputs), inplace=True)\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x), inplace=True) \n",
    "        \n",
    "        \n",
    "        # TODO 3\n",
    "        # Write the forward procedure to obtain the\n",
    "        # mean and the log var of the posterior p(z | x)\n",
    "        z_mean    = self.fc_mean(x)\n",
    "        z_log_var = self.fc_log_var(x)\n",
    "        \n",
    "        # TODO 4\n",
    "        # use the mean the log_var to sample from \n",
    "        # the posterior distribution p(z | x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        \n",
    "        return z_mean, z_log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=2, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        latent_dim\n",
    "            dimension of the latent variable\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "            \n",
    "        # define network architecture\n",
    "        self.fc1 = nn.Linear(latent_dim, 7 * 7 * 64)\n",
    "        self.convtrans1 = nn.ConvTranspose2d(64, 64, kernel_size=4, padding=1, stride=2)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(64, 32, kernel_size=4, padding=1, stride=2)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(32, 1, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs\n",
    "            tensor in the latent space\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            reconstructed tensor from input latent \n",
    "            input representation\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(inputs), inplace=True)\n",
    "        x = x.view(x.shape[0], 64, 7, 7)\n",
    "        x = F.relu(self.convtrans1(x), inplace=True)\n",
    "        x = F.relu(self.convtrans2(x), inplace=True)\n",
    "        x = self.sigmoid(self.convtrans3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Module\n",
    "\n",
    "The variational loss contains a KL regularization term that has a closed for two normal distribution (the standard normal prior $p(z)$ and the posterior normal $p(z|x)$)\n",
    "\n",
    "$$\n",
    "    KL(p(z|x) || p(z)) = \\sum_{i} -\\frac{1}{2} [z_{log-var, i} - z_{mean, i}^2 - \\exp(z_{log-var, i}) + 1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        encoder\n",
    "            encoder module\n",
    "        decoder\n",
    "            decoder module\n",
    "        \"\"\"\n",
    "        \n",
    "        super(VAE, self).__init__(**kwargs)         \n",
    "        # define device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # architecture\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.decoder = decoder.to(self.device)\n",
    "        \n",
    "        # kl divergence regularizer\n",
    "        self.kl_loss = None\n",
    "       \n",
    "        \n",
    "    def forward(self, inputs: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs\n",
    "            tensor in the input space B x C x H x W\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            reconstruction the the input tensor B x C x H x W\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        rec_inputs = self.decoder(z)\n",
    "        \n",
    "        # TODO 6\n",
    "        # Compute kl divergence regularization loss\n",
    "        # 1. Use the formula and first obtain a vector of size (B, latent_dim)\n",
    "        # 2. Do the summation over the first dimension\n",
    "        # 3. Compute the bacth mean\n",
    "        # \n",
    "        # We will use this in the training loop\n",
    "        self.kl_loss =  - 0.5 * (z_log_var - torch.square(z_mean) - torch.exp(z_log_var) + 1.) # here you should have vector \n",
    "#         print(self.kl_loss.size())\n",
    "        self.kl_loss =  torch.sum(self.kl_loss, dim=1) # sum over the dimension 1 \n",
    "#         print(self.kl_loss)\n",
    "        self.kl_loss =  torch.mean(self.kl_loss) # compute the mean of the batch\n",
    "#         print(self.kl_loss)\n",
    "        \n",
    "        return rec_inputs\n",
    "    \n",
    "    \n",
    "    def compile(self, optimizer: Type[torch.optim.Optimizer], \n",
    "                loss: Type[torch.nn.modules.loss._Loss], lr: float = 1e-3):\n",
    "        \"\"\"\n",
    "        Compile function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        optimizer\n",
    "            class of the optimizer (e.g. torch.optim.Adam)\n",
    "        loss\n",
    "            class of the loss (e.g. torch.loss.BCELoss)\n",
    "        \"\"\"\n",
    "        self.optimizer = optimizer(self.parameters(), lr=lr)\n",
    "        self.loss = loss(reduction=\"sum\")\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def __running_loss(r_loss: float, loss: float) -> float:\n",
    "        \"\"\"\n",
    "        Update running loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        r_loss\n",
    "            current running loss\n",
    "        loss\n",
    "            current loss\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Updated running loss\n",
    "        \"\"\"\n",
    "        \n",
    "        r_loss = loss if r_loss is None else (0.99 * r_loss + 0.01 * loss)\n",
    "        return r_loss\n",
    "    \n",
    "    \n",
    "    def train_step(self, x: torch.tensor) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Performs a training step\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x\n",
    "            batch of input data B x C x H x W\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple containing total loss, reconstruction loss, and KL loss\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train()\n",
    "        x = x.to(self.device)\n",
    "        \n",
    "        # compute the reconstruction loss\n",
    "        rec_x = self.forward(x)\n",
    "        rec_loss = self.loss(rec_x, x) / x.shape[0]\n",
    "        \n",
    "        # TODO 7\n",
    "        # Compute the final loss as the sum between\n",
    "        # the reconstruction loss and the kl regularization loss\n",
    "        loss = rec_loss + self.kl_loss\n",
    "\n",
    "        # gradient step\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item(), rec_loss.item(), self.kl_loss.item()\n",
    "\n",
    "    \n",
    "    def fit(self, dataset: Dataset, batch_size: int, epochs: int, \n",
    "            num_workers: int = 4, log_int: int = 100):\n",
    "        \"\"\"\n",
    "        Training loop\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset\n",
    "            training dataset\n",
    "        batch_size\n",
    "            training batch size\n",
    "        epochs\n",
    "            number of training epochs\n",
    "        num_workers\n",
    "            number of workers for dataloader\n",
    "        log_int\n",
    "            logging interval\n",
    "        \"\"\"\n",
    "        \n",
    "        # define dataloader\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=num_workers)\n",
    "        \n",
    "        # running loss\n",
    "        r_loss = None\n",
    "        r_rec_loss = None\n",
    "        r_kl_loss = None\n",
    "        \n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for step, data in enumerate(dataloader):\n",
    "                X, _ = data\n",
    "                loss, rec_loss, kl_loss = self.train_step(X)\n",
    "                \n",
    "                # update running loss\n",
    "                r_loss = VAE.__running_loss(r_loss, loss)\n",
    "                r_rec_loss = VAE.__running_loss(r_rec_loss, rec_loss)\n",
    "                r_kl_loss = VAE.__running_loss(r_kl_loss, kl_loss)\n",
    "                \n",
    "                # logging\n",
    "                if step % log_int == 0:\n",
    "                    print(\"Epoch: %d\\t Step: %d\\t Loss: %.3f\\t RecLoss: %.3f\\t KLLoss: %.3f\"\\\n",
    "                          % (epoch, step, r_loss, r_rec_loss, r_kl_loss))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Step: 0\t Loss: 514.278\t RecLoss: 514.250\t KLLoss: 0.028\n",
      "Epoch: 0\t Step: 500\t Loss: 186.611\t RecLoss: 186.333\t KLLoss: 0.278\n",
      "Epoch: 1\t Step: 0\t Loss: 180.516\t RecLoss: 180.234\t KLLoss: 0.282\n",
      "Epoch: 1\t Step: 500\t Loss: 176.968\t RecLoss: 176.645\t KLLoss: 0.323\n",
      "Epoch: 2\t Step: 0\t Loss: 174.088\t RecLoss: 173.740\t KLLoss: 0.348\n",
      "Epoch: 2\t Step: 500\t Loss: 171.609\t RecLoss: 171.250\t KLLoss: 0.358\n",
      "Epoch: 3\t Step: 0\t Loss: 170.834\t RecLoss: 170.468\t KLLoss: 0.367\n",
      "Epoch: 3\t Step: 500\t Loss: 169.098\t RecLoss: 168.734\t KLLoss: 0.364\n",
      "Epoch: 4\t Step: 0\t Loss: 168.979\t RecLoss: 168.630\t KLLoss: 0.349\n",
      "Epoch: 4\t Step: 500\t Loss: 167.930\t RecLoss: 167.589\t KLLoss: 0.341\n"
     ]
    }
   ],
   "source": [
    "# define transformation\n",
    "# feel free to add any other transformations\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# load the dateset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# define the autoencoder\n",
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "vae = VAE(enc, dec)\n",
    "\n",
    "# define optimizer and reconstruction loss\n",
    "# notice that the kl loss is incorporated into\n",
    "# the model itself\n",
    "optimizer = torch.optim.Adam\n",
    "loss_fn = torch.nn.BCELoss\n",
    "\n",
    "# compile the model\n",
    "vae.compile(optimizer=optimizer, loss=loss_fn, lr=1e-3)\n",
    "\n",
    "# fit the model\n",
    "vae.fit(trainset, batch_size=64, epochs=30, log_int=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "For the visualization procedure, we will sample from an uniform grid $[-1, 1] \\times [-1, 1]$ and we will pass this latent representation through the decoder to generate images in of size $28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(x: torch.tensor, nrow):\n",
    "    \"\"\"\n",
    "    Plots a batch of reconstructed data in a \n",
    "    grid formation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        batch of reconstructed data B x C x H x W\n",
    "    nrow\n",
    "        number of elements in a row\n",
    "    \"\"\"\n",
    "    img = torchvision.utils.make_grid(x, nrow=nrow)\n",
    "    npimg = np.transpose(img.numpy(), (1, 2, 0))\n",
    "\n",
    "    plt.figure(figsize = (15, 15))\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8\n",
    "# Run the visualization procedure from below\n",
    "\n",
    "# construct sample grid\n",
    "scale = 1.\n",
    "samples = 20 \n",
    "\n",
    "x = np.linspace(-scale, scale, samples)\n",
    "y = np.linspace(-scale, scale, samples)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xv, yv = xv.reshape(-1, 1), yv.reshape(-1, 1)\n",
    "\n",
    "# construct the laent space\n",
    "z = np.concatenate([xv, yv], axis=1)\n",
    "z = torch.tensor(z)\n",
    "\n",
    "# set model to evauation\n",
    "vae = vae.eval()\n",
    "z = z.float().to(vae.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = vae.decoder(z).cpu()\n",
    "    \n",
    "# plot the image\n",
    "plot_img(x, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}